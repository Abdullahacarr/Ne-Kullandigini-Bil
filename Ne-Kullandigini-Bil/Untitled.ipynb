{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linki Giriniz:https://www.watsons.com.tr/p/ogx-dolgunlastirici-biotin-kolajen-sampuan-385-ml-16799\n",
      "Ürün Adını Giriniz:OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "Çok etkili \n",
      "Ürünün  dolgunlaştırıcı özelliği yanında onarıcı bir özelliği de var. Benim saçım ince telli; taranması da şekil vermesi de pek kolay değil ama biotin collagen ile harika bir sonuç aldım ve almaya devam ediyorum.,OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "\n",
      "Ogx Dolgunlaştrıcı\n",
      "Bu şampuan gerçekten saçlarımı dolgunlaştırıyor, hatta öyle hale geldi ki çok dolgunlaştı ben de kullanmıyorum artık, zaten dalgalı bir saçım var kraliçeye dönmek istemedim doğrusu. Çok ince telli ve düz saçların kullanmasını öneririm. Üründe sorun yok benim seçimim yanlış.,OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "\n",
      "abartıldığı gibi değil\n",
      "ilk başlarda memnunum sandım ama saçlarımı çok sertleştirdi dolgunlaştırmadı kuruttu memnun kalmadım bırakınca doğru karar verdiğimi anladım,OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "\n",
      "Beğendim\n",
      "Şampuan gerçekten güzel saç uzatıcı ve dolgunlaştırıcı etkisi var memnunum tek bir sorun var yeni yıkayıp kuruttugumda bile bi yıkanmamış rahatsızlığı veriyor ve saçımı ertesi gün yine yıkamak zorunda oluyorum yaz için sorun yok ama çabuk yaglandırması kışın sorun olabiliyor,OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "\n",
      "etkili değil \n",
      "herkesin saç tipi farklıdır bende güzel etki göstermedi faydasını görmedim saçımı çok sert yaptı saçları aşırı kurutuyor,OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def watsons(link,adi):\n",
    "    #watsans\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    url = link\n",
    "    url_oku = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(url_oku, 'html.parser')\n",
    "    icerik = soup.find_all('div',attrs={'class':'review-balloon bg-site-light-gray my-2 rounded p-2'})\n",
    "    fo = open(\"deneme.txt\", \"a+\",encoding=\"utf-8\")\n",
    "    c=\"\"\n",
    "    for a in icerik:\n",
    "        c+=a.text.strip().replace(\"  \",\"\")+\",\"+adi+'\\n\\n'\n",
    "    print(c)\n",
    "    fo.write(c)\n",
    "    fo.close()\n",
    "    return\n",
    "def hepsiburada(link,adi):    \n",
    "    #hepsiburada\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    url = link\n",
    "    url_oku = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(url_oku, 'html.parser')\n",
    "    icerik = soup.find_all('p',attrs={'class':'review-text'})\n",
    "   \n",
    "\n",
    "    fo = open(\"deneme.txt\", \"a+\",encoding=\"utf-8\")\n",
    "    c=\"\"\n",
    "   \n",
    "    for a in icerik:\n",
    "        c+=a.text.strip().replace(\"  \",\"\")+\",\"+adi+'\\n\\n'\n",
    "    \n",
    "    print(c)\n",
    "    fo.write(c)\n",
    "    fo.close()\n",
    "    \n",
    "def suslu(link,adi):\n",
    "    #süslü sözlük\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request\n",
    "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "\n",
    "    url = link\n",
    "    headers={'User-Agent':user_agent,} \n",
    "\n",
    "    request=urllib.request.Request(url,None,headers) \n",
    "    response = urllib.request.urlopen(request)\n",
    "    data = response.read() \n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    icerik = soup.find_all('div',attrs={'class':'post-body buttonable'})\n",
    "    fo = open(\"deneme.txt\", \"a+\",encoding=\"utf-8\")\n",
    "    c=\"\"\n",
    "    \n",
    "    for a in icerik:\n",
    "        c+=a.text.strip().replace(\"  \",\"\")+\",\"+adi+'\\n\\n'\n",
    "    print(c)\n",
    "    fo.write(c)\n",
    "    fo.close()\n",
    "\n",
    "def trendyol(link,adi):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request\n",
    "    import pandas as pd\n",
    "    url = link\n",
    "    url_oku = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(url_oku, 'html.parser')\n",
    "    icerik = soup.find_all('div',attrs={'class':'rnr-com-cn'})\n",
    "    \n",
    "\n",
    "    fo = open(\"deneme.txt\", \"a+\",encoding=\"utf-8\")\n",
    "    c=\"\"\n",
    "    \n",
    "    for a in icerik:\n",
    "    \n",
    "         c+=a.text.strip().replace(\"  \",\"\")+\",\"+adi+'\\n\\n'\n",
    "    \n",
    "    print(c)\n",
    "    fo.write(c)\n",
    "    fo.close()\n",
    "link=input(\"Linki Giriniz:\")\n",
    "adi=input(\"Ürün Adını Giriniz:\")\n",
    "if(\"watsons\" in link):\n",
    "    watsons(link,adi)\n",
    "elif(\"hepsiburada\" in link):\n",
    "    hepsiburada(link,adi)\n",
    "elif(\"suslusozluk\" in link):\n",
    "    suslu(link,adi)\n",
    "elif(\"trendyol\" in link):\n",
    "    trendyol(link,adi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yorumu giriniz :Cok guzel cok begendim\n",
      "puanı giriniz : 5\n",
      "bizim tahminimiz [5.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.metrics import recall_score\n",
    "\n",
    "data = pd.read_csv(\"dosya.txt\", engine='python', encoding='utf-8')\n",
    "data = data.dropna()\n",
    "#print(data)\n",
    "\n",
    "sentences_training = [doc for doc in data.iloc[:,0]]\n",
    "classification_training = [doc for doc in data.iloc[:,2]]\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', lowercase = True)\n",
    "\n",
    "sen_train_vector = vectorizer.fit_transform(sentences_training)\n",
    "#print(sen_train_vector.toarray())\n",
    "\n",
    "clf = GaussianNB()\n",
    "yor=input(\"yorumu giriniz :\")\n",
    "puan=input(\"puanı giriniz : \")\n",
    "\n",
    "model = clf.fit(X=sen_train_vector.toarray(), y=classification_training)\n",
    "\n",
    "sen_test_vector = vectorizer.transform([yor])\n",
    "y_pred = model.predict(sen_test_vector.toarray())\n",
    "#puan=[1]\n",
    "\n",
    "\n",
    "print(\"bizim tahminimiz %s\" % y_pred)\n",
    "#test=recall_score(puan,y_pred.shape, average='micro')\n",
    "#if(test==1):\n",
    "#    print(\"doğru bildiniz\")\n",
    "#   print(test)\n",
    "#else :\n",
    "#    print(\"yanlış bildiniz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urun_adı</th>\n",
       "      <th>puanı</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>henüz ilk kutumdayım ancak çok memnunum. tabi ki saçların müthiş uzamasını yahut 10 katı hacme kavuşmasını beklemek yanlış olur ancak eski mısır püskülü saçlarımdan çok daha hacimli ve parlak saçlarım var ben bunu bu şampuana ve saç kremine bağlıyorum.30 liraya alınabilecek güzel bir şampuandır.</td>\n",
       "      <td>OGX Dolgunlaştırıcı Biotin&amp;Kolejen Şampuanı</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1 yıldır kullanıyorum çok memnunum değişiklik olsun diye revox Biotin Collagen Şampuana gectım fakat aşırı dökülme yaptı.. bu şampuandan 2 kere kullandım anında dökülmeyi kesti. Şampuan dan memnun kalmayanlar her şampuan her saça iyi gelmez bunu sizde biliyorsunuz ben şampuanımı buldum memnunum.</td>\n",
       "      <td>OGX Dolgunlaştırıcı Biotin&amp;Kolejen Şampuanı</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       urun_adı  \\\n",
       "yorum                                                                                             \n",
       "henüz ilk kutumdayım ancak çok memnunum. tabi k...  OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı   \n",
       "1 yıldır kullanıyorum çok memnunum değişiklik o...  OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı   \n",
       "\n",
       "                                                    puanı  \n",
       "yorum                                                      \n",
       "henüz ilk kutumdayım ancak çok memnunum. tabi k...    5.0  \n",
       "1 yıldır kullanıyorum çok memnunum değişiklik o...    5.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dosya.txt\", engine='python', encoding='utf-8')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "#kategorilerdeki ürün sayısı\n",
    "#data[\"urun_adı\"].value_counts()\n",
    "#data[\"urun_adı\"].value_counts()\n",
    "#data.filter(items=['OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı'], like='bbi', axis=0)\n",
    "#data[data.urun_adı\t == \"OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı\"]\n",
    "\n",
    "filter1 = data.loc[data['urun_adı'] == 'OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı']\n",
    "#filter1 = data.set_index(['OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı'])\n",
    "filter1.set_index('yorum').filter(like='çok memnunum', axis=0)\n",
    "#filter1.filter(regex ='[(Kokusu köpürmesi güzel)]')\n",
    "\n",
    "\n",
    "#mask = data['urun_adı'].isin(['OGX Dolgunlaştırıcı Biotin&Kolejen Şampuanı'])\n",
    "#mask[mask[\"yorum\"].str.contains(\"Kokusu köpürmesi güzel\")]\n",
    "#mask.set_index('yorum').filter(like='Kokusu köpürmesi güzel', axis=0)\n",
    "#data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gratis\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "url = \"https://www.gratis.com/pastel-day-long-lipcolor-kissproof-ruj/urun/Pastel1004?sku=10035782,https://www.hepsiburada.com/pastel-daylong-lipcolor-kissproof-20-likit-ruj-p-SGMAKOPST0025\"\n",
    "url_oku = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(url_oku, 'html.parser')\n",
    "icerik = soup.find_all('div',attrs={'class':'bv-content-summary-body-text'})\n",
    "#meta = soup.find_all('div',attrs={'class':'queue'})\n",
    "#fo = open(\"dosya.txt\", \"w\",encoding=\"utf-8\")\n",
    "c=\"\"\n",
    "#c+=\"Sentence,NegPos\\n\"\n",
    "for a in icerik:\n",
    "    c+=a.text.strip().replace(\"  \",\"\")+'\\n\\n'\n",
    "    \n",
    "print(c)\n",
    "#fo.write(c)\n",
    "#fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)\n",
    "accuracy_score(y_true, y_pred, normalize=False)\n",
    "\n",
    "import numpy as np\n",
    "accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
